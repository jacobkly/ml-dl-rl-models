{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14e544c-0794-4839-b345-fa4eeec1664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libaries\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from tensorflow import keras  \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, SimpleRNN  \n",
    "from keras.utils import to_categorical \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a2e5ab-7669-4b6b-b151-abc54c87c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Shape: (2820, 2)\n",
      "Target Shape: (2820, 1)\n"
     ]
    }
   ],
   "source": [
    "# load the 'monthly-sunspots.csv' dataset\n",
    "df = pd.read_csv('monthly-sunspots.csv')\n",
    "\n",
    "# extract Year and Month from the 'Month' column\n",
    "df['Year'] = df['Month'].str[:4].astype(int)\n",
    "df['Month'] = df['Month'].str[5:7].astype(int)\n",
    "\n",
    "# define the feature and targert variables\n",
    "X = df[['Year', 'Month']]\n",
    "y = df['Sunspots']\n",
    "\n",
    "# Process the time-series dataset\n",
    "X_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X) \n",
    "y = y_scaler.fit_transform(y.values.reshape(-1, 1)) \n",
    "\n",
    "# data analysis step to find shape\n",
    "print('Feature Shape:', X.shape)\n",
    "print('Target Shape:', y.shape)\n",
    "\n",
    "# reshape features to align with RNN model expectations (num_samples, time_steps, num_features)\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "# split the dataset into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48fb63da-f942-4158-b1df-37e48425dbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob Klymenko\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# set model parameters\n",
    "input_shape = (12, X.shape[2])\n",
    "units = 256\n",
    "dropout = 0.2\n",
    "\n",
    "# build the RNN model\n",
    "model = Sequential(\n",
    "    [\n",
    "        SimpleRNN(units=units, dropout=dropout, input_shape=input_shape),\n",
    "        Dense(1) # non-classficiation -> 1 dense layer\n",
    "    ]\n",
    ")\n",
    "\n",
    "# compile the model with mean squared error loss, Adam optimizer, and mean squared error (MSE)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdaf4b8-49cb-4dbc-8058-40fb81400c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0319 - mse: 0.0319\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0297 - mse: 0.0297 \n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - mse: 0.0296 \n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0292 - mse: 0.0292 \n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0298 - mse: 0.0298 \n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0288 - mse: 0.0288 \n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0290 - mse: 0.0290 \n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0318 - mse: 0.0318 \n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0288 - mse: 0.0288 \n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0296 - mse: 0.0296 \n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0307 - mse: 0.0307 \n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0308 - mse: 0.0308 \n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0300 - mse: 0.0300 \n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0290 - mse: 0.0290 \n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0289 - mse: 0.0289 \n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0297 - mse: 0.0297 \n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0290 - mse: 0.0290 \n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0293 - mse: 0.0293 \n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0301 - mse: 0.0301 \n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0289 - mse: 0.0289 \n",
      "\n",
      "Test Mean Squared Error (MSE):  0.028136132284998894\n"
     ]
    }
   ],
   "source": [
    "# define training parameters\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "# train the model on the training data with the specified number of epochs and batch size\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# evaluate the model of the test data\n",
    "_, mse = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "\n",
    "# print the MSE as a performance measure\n",
    "print('\\nTest Mean Squared Error (MSE): ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27871b9b-ac06-4517-a991-97ca4b854fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results:\n",
    "#\n",
    "# This problem was also pretty interesting as the dataset did not contain the need for \n",
    "# classification prediction, but rather sunspots which look like continuous values. After \n",
    "# extrating the year and month from the first time-series column and scaling both of them \n",
    "# with the MinMaxScaler from Sklearn as mentioned in the problem statement, it was \n",
    "# interesting to work through how to adjust the RNN model to the shape of the dataset.\n",
    "# However, testing different time step values for the input_shape variable overall did \n",
    "# not look like it affected the final performance of the mean squared error (MSE) value.\n",
    "#\n",
    "# Looking at the MSE value of approximately 0.028 with the understanding the sunspot ranges \n",
    "# from about 0 to 200, shows that the RNN model built in this file has a decent performance, as \n",
    "# it looks to be capturing some patterns throughout the dataset. However, it is not the best and \n",
    "# has room for improvement in reducing the error. I believe a of couple adjustment considerations \n",
    "# could be the time step, as for some reason it does not play a role here but should be, and the \n",
    "# data processing step is most likely incorrectly setting up the dataset for training. After \n",
    "# trying different hyper-parameters, this MSE value of about 0.028 is the best I can get. The \n",
    "# reason I chose MSE as both the loss function and metric is that the target variable, 'Sunspots', \n",
    "# is continuous rather than categorical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
