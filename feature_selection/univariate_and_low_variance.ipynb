{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef990db7-8271-49bb-9fc2-abbd959732ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from sklearn.feature_selection import SelectKBest  \n",
    "from sklearn.feature_selection import f_classif\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017b562d-5d44-40f2-8302-cec0a79a7ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape before cleaning: (7752, 24)\n",
      "Dataset shape after cleaning: (7585, 24)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('Bias_correction_ucl.csv')\n",
    "\n",
    "# drop the 'Date' feature as it's meaningless\n",
    "df = df.drop(columns='Date')\n",
    "\n",
    "# print the shape of dataset\n",
    "print('Dataset shape before cleaning:', df.shape)\n",
    "\n",
    "# clean the dataset by replacing negative values with NaN and dropping NaN values\n",
    "df.iloc[:, 2:] = df.iloc[:, 2:].mask(df.iloc[:, 2:] < 0)\n",
    "df = df.dropna()\n",
    "\n",
    "# print the shape of the dataset after cleaning\n",
    "print('Dataset shape after cleaning:', df.shape)\n",
    "\n",
    "# define the feature variables in the dataset\n",
    "X = df.iloc[:, :-2].values\n",
    "\n",
    "# define the target variable for this task\n",
    "y = df.iloc[:, -2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a19063a-b7e5-43c3-aa9b-3d2c07920e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after univariate feature selection: (7585, 5)\n",
      "Five highest scoring columns after univariate feature selection (highest scores first):\n",
      "   ['LDAPS_Tmax_lapse', 'Present_Tmax', 'LDAPS_Tmin_lapse', 'LDAPS_CC3', 'LDAPS_CC2']\n"
     ]
    }
   ],
   "source": [
    "# apply univariate feature selection\n",
    "\n",
    "# initialize SelectKBest with ANOVA F-value test to select the 7 best features\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "\n",
    "# apply the SelectKBest object to the feature matrix and target vector\n",
    "X_uni = selector.fit_transform(X, y)\n",
    "\n",
    "# show dimensions of the feature matrix after feature selection\n",
    "print('Dataset shape after univariate feature selection:', X_uni.shape)\n",
    "\n",
    "# show the columns after the feature selection in ranking order\n",
    "scores = selector.scores_ # get scores for all features\n",
    "indices = np.argsort(scores)[-5:][::-1] # get indices of selected features in descending order\n",
    "features = df.columns[:-2][indices] # get the names of the features\n",
    "print('Five highest scoring columns after univariate feature selection (highest scores first):\\n  ', \n",
    "      features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adee6e22-827e-4265-bf1b-d958efaeba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five highest scoring columns after low variance feature selection (highest scores first):\n",
      "   ['Solar radiation', 'DEM', 'LDAPS_LH', 'LDAPS_RHmin', 'station']\n"
     ]
    }
   ],
   "source": [
    "# apply low variance feature selection\n",
    "\n",
    "# instantiate the VarianceThreshold object\n",
    "sel = VarianceThreshold(threshold=0.2)\n",
    "\n",
    "# apply the VarianceThreshold to the dataset\n",
    "X_low = sel.fit_transform(X)\n",
    "\n",
    "# get columns of the selected features\n",
    "columns = df.columns[:-2][sel.get_support()]\n",
    "\n",
    "# pick the top five features\n",
    "variances = X.var(axis=0)\n",
    "indices = variances.argsort()[::-1]\n",
    "columns = df.columns[:-2][indices][:5]\n",
    "\n",
    "# print the selected columns\n",
    "print('Five highest scoring columns after low variance feature selection (highest scores first):\\n  ', \n",
    "      columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4522c7c9-8939-45ea-a9d7-a313d5dfffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results:\n",
    "#\n",
    "# I used the univariate and low variance feature selections because they both were able to \n",
    "# process datasets with continuous values for this dataset. Low variance feature selection \n",
    "# didn't need to be modified, however, univariate feature selection did have to change from \n",
    "# 'chi2' scoring function to 'f_classif' as the latter can process continuous values.\n",
    "#\n",
    "# From these two feature selection methods, both of them chose different sets of five \n",
    "# features. It is interesting to see these results, as the univariate feature selection \n",
    "# process chose the features using both the feature and target variable and from my \n",
    "# understanding it looks at their relationship together. Meanwhile, the low variance \n",
    "# feature selection only looks at the feature variables. With this, these two different \n",
    "# sets of features selected is different but can include new insight into what features\n",
    "# should be selected when going forth and training a model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
